# data.py

## generate gaussian mixture
This function generates a gaussian mixture
I am doing this because I actually don't know how it is done computationally
### Inputs 
```
n_samples, n_components=8, dim=2, std_scale=0.1
```
n_samples: number of samples to generate

n_components: number of components in a sample?

dim: dimensions/space

std_scale: scaline std?

### variables
```
angles = np.linspace(0, 2 * np.pi, n_components, endpoint=False)
means = 1.5 * np.array([[np.cos(a), np.sin(a)] for a in angles])
stds = np.random.uniform(0.1, std_scale, size=(n_components, dim))
```

angles = generates **n_components** points around a circle (for the angles)

means = stores positions for the points generated by **angles**

stds = draws random numbers from between 0.1 and std_scale in a array of size

```
component_choices = np.random.choice(n_components, size=n_samples)
samples = np.empty((n_samples, dim))
```

component_choices = pick a random integer (0 to n_components) n_samples times

samples = empty array of size n_samples x dim

### for loop

iterating over n_components, masks takes the random values selected by **component_choices** and then WHAT 

## generate rectangle data

### inputs
n_samples, width, height
is self explanatory

# model.py

## scorenet
looks like I have to look up what scorenet is

time mlp seems to convert time_dim into a higher dimension

net takes input dim + time dim, converts it to hidden dim, and then back down to input dimensions

forward 
... concat?

## sde.py
are these properties of sdes


## trainer.py
### scare matching loss
I need more help but I think this is the iterative noise addition thingy

### train diffusion model

